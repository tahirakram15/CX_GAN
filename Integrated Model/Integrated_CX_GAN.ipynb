{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Integrated_CX-GAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SO5tqFYa6oo_",
        "colab_type": "text"
      },
      "source": [
        "**Specifying the TensorFlow version for COLAB**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_ILThMc6uDg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDZonsbIKIsm",
        "colab_type": "text"
      },
      "source": [
        "**Connect To Drive (For COLAB)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSquw5q2KLJ0",
        "colab_type": "code",
        "outputId": "5ddec12e-89e7-4d3d-f8cd-da07a8366913",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwskK9Zi3Zso",
        "colab_type": "text"
      },
      "source": [
        "Install Keras-Contrib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y28xOods3dVS",
        "colab_type": "code",
        "outputId": "f316f5c4-9663-421a-d371-7a4b76357bad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "pip install git+https://www.github.com/keras-team/keras-contrib.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-7_vk9ext\n",
            "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-7_vk9ext\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-contrib==2.0.8) (2.2.5)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.17.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.4.1)\n",
            "Building wheels for collected packages: keras-contrib\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-cp36-none-any.whl size=101064 sha256=026b28009a393b4615253ce7594048c5801642dbcee09d030b3e3948f0535e05\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-halybi1k/wheels/11/27/c8/4ed56de7b55f4f61244e2dc6ef3cdbaff2692527a2ce6502ba\n",
            "Successfully built keras-contrib\n",
            "Installing collected packages: keras-contrib\n",
            "Successfully installed keras-contrib-2.0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQiVLzpt-4sQ",
        "colab_type": "text"
      },
      "source": [
        "Import All Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-3n5fQ87ATc",
        "colab_type": "code",
        "outputId": "8fb3c8ab-2898-4464-8696-b9788b7cbccf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#from keras.datasets import mnist\n",
        "import keras\n",
        "#from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
        "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
        "#from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n",
        "from keras.layers import concatenate, Concatenate, UpSampling2D, Conv2D, Conv2DTranspose, MaxPooling2D, Activation, Flatten, Dense, Input, BatchNormalization, Dropout, Reshape\n",
        "#from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "#from keras.layers.convolutional import UpSampling2D, Conv2D\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import Adam\n",
        "import datetime\n",
        "import sys\n",
        "#from data_loader import DataLoader\n",
        "\n",
        "import h5py\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "from __future__ import print_function, division\n",
        "import scipy\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olxA9_Nz7N8c",
        "colab_type": "text"
      },
      "source": [
        "**Load DataSet and Split into train and test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8PZCfR95BgR",
        "colab_type": "code",
        "outputId": "8848fcee-e452-4067-a316-12fd796dcf2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "base_path = '/content/drive/My Drive/DataSets/Brain/processedBrats_FullBrain/V3_Brats2017'\n",
        "with h5py.File(os.path.join(base_path, 'v2_withlabel01_imgs_without_masks-imgs_with_masks-imgs_masks_zscore_norm__float32.hdf5'), 'r') as f:\n",
        "  imgs_without_masks = f['imgs_without_masks'].value\n",
        "  imgs_with_masks = f['imgs_with_masks'].value\n",
        "  imgs_masks = f['imgs_masks'].value\n",
        "print('DataSet Loaded Successfully')\n",
        "\n",
        "imgs_without_masks = imgs_without_masks.reshape(-1, imgs_without_masks.shape[1], imgs_without_masks.shape[2], 1)\n",
        "imgs_with_masks = imgs_with_masks.reshape(-1, imgs_with_masks.shape[1], imgs_with_masks.shape[2], 1)\n",
        "imgs_masks = imgs_masks.reshape(-1, imgs_masks.shape[1], imgs_masks.shape[2], 1)\n",
        "#####\n",
        "\n",
        "test_start = 7\n",
        "test_size = 10#set test size. \n",
        "\n",
        "imgs_with_masks_test = imgs_with_masks[test_start:test_start+test_size]\n",
        "imgs_with_masks = np.delete(imgs_with_masks, np.arange(test_start, test_start+test_size), axis=0)\n",
        "\n",
        "imgs_masks_test = imgs_masks[test_start:test_start+test_size]\n",
        "imgs_masks = np.delete(imgs_masks, np.arange(test_start, test_start+test_size), axis=0)\n",
        "\n",
        "test_start = 0\n",
        "test_size = 10#set test size.\n",
        "imgs_without_masks_test = imgs_without_masks[test_start:test_start+test_size]\n",
        "imgs_without_masks = np.delete(imgs_without_masks, np.arange(test_start, test_start+test_size), axis=0)\n",
        "\n",
        "print('imgs_with_masks_test', imgs_with_masks_test.shape)\n",
        "print('imgs_with_masks', imgs_with_masks.shape)\n",
        "print('imgs_masks_test', imgs_masks_test.shape)\n",
        "print('imgs_masks', imgs_masks.shape)\n",
        "print('imgs_without_masks_test', imgs_without_masks_test.shape)\n",
        "print('imgs_without_masks', imgs_without_masks.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DataSet Loaded Successfully\n",
            "imgs_with_masks_test (10, 256, 256, 1)\n",
            "imgs_with_masks (2701, 256, 256, 1)\n",
            "imgs_masks_test (10, 256, 256, 1)\n",
            "imgs_masks (2701, 256, 256, 1)\n",
            "imgs_without_masks_test (10, 256, 256, 1)\n",
            "imgs_without_masks (453, 256, 256, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hf6WuGIEjM9l",
        "colab_type": "text"
      },
      "source": [
        "**Cycle GAN** ***(UNET)***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuATKe0PxkLS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def overlayMaskonImg(img, msk):\n",
        "    image = (((img - np.min(img))/(np.max(img) - np.min(img)))*255).astype('uint8')\n",
        "    mask = (((msk - np.min(msk))/(np.max(msk) - np.min(msk)))*255).astype('uint8')\n",
        "    mask = np.where(mask>0,255,0).astype('uint8')\n",
        "    image = cv2.merge([image, image, image])\n",
        "    mask = cv2.merge([mask, np.zeros(mask.shape).astype('uint8'), np.zeros(mask.shape).astype('uint8')])\n",
        "    indices = np.where(mask==255)\n",
        "    mask[indices[0], indices[1], :] = [255, 0, 0]    \n",
        "    \n",
        "    alpha = 0.6\n",
        "    #cv2.addWeighted(mask, alpha, image, 1 - alpha, 0, image)\n",
        "    cv2.addWeighted(mask, alpha, image, 1, 0, image)\n",
        "    \n",
        "    return image\n",
        "\n",
        "def getHeatMap(bimg, msk):\n",
        "  image = bimg\n",
        "  image = (image - np.min(image))/(np.max(image) - np.min(image))\n",
        "  image = (image*255).astype('uint8')\n",
        "  mask = msk\n",
        "  cmap = plt.get_cmap('jet')\n",
        "  rgba_img = cmap(mask)\n",
        "  rgb_img = np.delete(rgba_img, 3, 2)\n",
        "\n",
        "  alpha = 0.4\n",
        "  output = cv2.merge([image, image, image])#image.copy().astype('uint8')\n",
        "  overlay = (rgb_img.copy()*255).astype('uint8')\n",
        "  foutput = cv2.addWeighted(overlay, alpha, output, 1 - alpha, 0, output)\n",
        "\n",
        "  return foutput\n",
        "  \n",
        "def getbinaryMaskFromHeatMap(heatmap):\n",
        "  img1 = heatmap.copy()\n",
        "  image_hsv = cv2.cvtColor(img1, cv2.COLOR_BGR2HSV)\n",
        "  h, _, _ = cv2.split(image_hsv)\n",
        "  mask = cv2.inRange(h, 95, 1000)\n",
        "  blob = cv2.bitwise_and(img1, img1, mask=mask)\n",
        "\n",
        "  foutput = np.where(cv2.cvtColor(blob, cv2.COLOR_BGR2GRAY) > 10 ,1, 0)\n",
        "  return blob, foutput"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkADjXNnN87X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CX_GAN():\n",
        "    def __init__(self):\n",
        "        self.img_rows = 256\n",
        "        self.img_cols = 256\n",
        "        self.channels = 1\n",
        "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
        "\n",
        "        # Calculate output shape of D (PatchGAN)\n",
        "        patch = int(self.img_rows / 2**4)\n",
        "        self.disc_patch = (patch, patch, 1)\n",
        "\n",
        "        # Number of filters in the first layer of G and D\n",
        "        self.gf = 32\n",
        "        self.df = 64\n",
        "\n",
        "        # Loss weights\n",
        "        self.lambda_cycle = 10.0                    # Cycle-consistency loss\n",
        "        self.lambda_id = 0.1 * self.lambda_cycle    # Identity loss\n",
        "\n",
        "        optimizer = Adam(0.0002, 0.5)\n",
        "\n",
        "        # Build and compile the discriminators\n",
        "        self.d_A = self.build_discriminator()\n",
        "        self.d_B = self.build_discriminator()\n",
        "        self.d_A.compile(loss='mse',\n",
        "            optimizer=optimizer,\n",
        "            metrics=['accuracy'])\n",
        "        self.d_B.compile(loss='mse',\n",
        "            optimizer=optimizer,\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "        #-------------------------\n",
        "        # Construct Computational\n",
        "        #   Graph of Generators\n",
        "        #-------------------------\n",
        "\n",
        "        # Build the generators\n",
        "        self.g_AB = self.build_generator()\n",
        "        self.g_BA = self.build_generator()\n",
        "\n",
        "        # Input images from both domains\n",
        "        img_A = Input(shape=self.img_shape)\n",
        "        img_B = Input(shape=self.img_shape)\n",
        "\n",
        "        # Translate images to the other domain\n",
        "        fake_B = self.g_AB(img_A)\n",
        "        fake_A = self.g_BA(img_B)\n",
        "        fake_A = keras.layers.Add()([fake_A, img_B])\n",
        "        # Translate images back to original domain\n",
        "        reconstr_A = self.g_BA(fake_B)\n",
        "        reconstr_A = keras.layers.Add()([reconstr_A, fake_B])\n",
        "        reconstr_B = self.g_AB(fake_A)\n",
        "        # Identity mapping of images\n",
        "        img_A_id = self.g_BA(img_A)\n",
        "        img_A_id = keras.layers.Add()([img_A_id, img_A])\n",
        "        img_B_id = self.g_AB(img_B)\n",
        "\n",
        "        # For the combined model we will only train the generators\n",
        "        self.d_A.trainable = False\n",
        "        self.d_B.trainable = False\n",
        "\n",
        "        # Discriminators determines validity of translated images\n",
        "        valid_A = self.d_A(fake_A)\n",
        "        valid_B = self.d_B(fake_B)\n",
        "\n",
        "        # Combined model trains generators to fool discriminators\n",
        "        self.combined = Model(inputs=[img_A, img_B],\n",
        "                              outputs=[ valid_A, valid_B,\n",
        "                                        reconstr_A, reconstr_B,\n",
        "                                        img_A_id, img_B_id ])\n",
        "        self.combined.compile(loss=['mse', 'mse',\n",
        "                                    'mae', 'mae',\n",
        "                                    'mae', 'mae'],\n",
        "                            loss_weights=[  1, 1,\n",
        "                                            self.lambda_cycle, self.lambda_cycle,\n",
        "                                            self.lambda_id, self.lambda_id ],\n",
        "                            optimizer=optimizer)\n",
        "\n",
        "    def random_crop(self, image, imgs_count):\n",
        "      cropped_image = tf.image.random_crop(\n",
        "      image, size=[imgs_count, self.img_cols, self.img_rows, self.channels])\n",
        "      return cropped_image\n",
        "\n",
        "    def random_jitter(self, image):\n",
        "        # resizing to 286 x 286 x 3\n",
        "        imgs_count = image.shape[0]\n",
        "        image = tf.image.resize_images(image, [self.img_cols, self.img_rows],\n",
        "                                method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "\n",
        "        # randomly cropping to 256 x 256 x 3\n",
        "        image = self.random_crop(image, imgs_count)\n",
        "\n",
        "        # random mirroring\n",
        "        with tf.Session() as sess:\n",
        "          image = tf.image.random_flip_left_right(image).eval()#self.sess.run(tf.image.random_flip_left_right(image))#tf.image.random_flip_left_right(image).eval()\n",
        "          \n",
        "        return image\n",
        "\n",
        "    def getRandomindexes(self, end, sampleSize, _replace = False):\n",
        "        return np.random.choice(np.asarray(range(end)), sampleSize, replace = _replace)\n",
        "\n",
        "    def build_generator(self):\n",
        "        \"\"\"U-Net Generator\"\"\"\n",
        "\n",
        "        def conv2d(layer_input, filters, f_size=4):\n",
        "            \"\"\"Layers used during downsampling\"\"\"\n",
        "            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
        "            d = LeakyReLU(alpha=0.2)(d)\n",
        "            d = InstanceNormalization()(d)\n",
        "            return d\n",
        "\n",
        "        def deconv2d(layer_input, skip_input, filters, f_size=4, dropout_rate=0):\n",
        "            \"\"\"Layers used during upsampling\"\"\"\n",
        "            u = UpSampling2D(size=2)(layer_input)\n",
        "            u = Conv2D(filters, kernel_size=f_size, strides=1, padding='same', activation='relu')(u)\n",
        "            if dropout_rate:\n",
        "                u = Dropout(dropout_rate)(u)\n",
        "            u = InstanceNormalization()(u)\n",
        "            u = Concatenate()([u, skip_input])\n",
        "            return u\n",
        "\n",
        "        # Image input\n",
        "        d0 = Input(shape=self.img_shape)\n",
        "\n",
        "        # Downsampling\n",
        "        d1 = conv2d(d0, self.gf)\n",
        "        d2 = conv2d(d1, self.gf*2)\n",
        "        d3 = conv2d(d2, self.gf*4)\n",
        "        d4 = conv2d(d3, self.gf*8)\n",
        "\n",
        "        # Upsampling\n",
        "        u1 = deconv2d(d4, d3, self.gf*4)\n",
        "        u2 = deconv2d(u1, d2, self.gf*2)\n",
        "        u3 = deconv2d(u2, d1, self.gf)\n",
        "\n",
        "        u4 = UpSampling2D(size=2)(u3)\n",
        "        output_img = Conv2D(self.channels, kernel_size=4, strides=1, padding='same', activation='tanh')(u4)\n",
        "\n",
        "        return Model(d0, output_img)\n",
        "\n",
        "    def build_discriminator(self):\n",
        "\n",
        "        def d_layer(layer_input, filters, f_size=4, normalization=True):\n",
        "            \"\"\"Discriminator layer\"\"\"\n",
        "            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
        "            d = LeakyReLU(alpha=0.2)(d)\n",
        "            if normalization:\n",
        "                d = InstanceNormalization()(d)\n",
        "            return d\n",
        "\n",
        "        img = Input(shape=self.img_shape)\n",
        "\n",
        "        d1 = d_layer(img, self.df, normalization=False)\n",
        "        d2 = d_layer(d1, self.df*2)\n",
        "        d3 = d_layer(d2, self.df*4)\n",
        "        d4 = d_layer(d3, self.df*8)\n",
        "\n",
        "        validity = Conv2D(1, kernel_size=4, strides=1, padding='same')(d4)\n",
        "\n",
        "        return Model(img, validity)\n",
        "\n",
        "    def train(self, epochs, ModelSavePath, model_save_intervel=5, restoreFrom = None, batch_size=1, sample_interval=50):\n",
        "        basePath_ModelSave = ModelSavePath\n",
        "        run_ModelSave = ''\n",
        "        epoch_start = 0\n",
        "        if restoreFrom is None:\n",
        "          if not os.path.exists(basePath_ModelSave):\n",
        "            os.mkdir(basePath_ModelSave)\n",
        "\n",
        "          if len(os.listdir(basePath_ModelSave)) == 0:\n",
        "            vName = 0\n",
        "          else:\n",
        "            vName = [int(x[-1]) for x in sorted(os.listdir(basePath_ModelSave))]\n",
        "          run_ModelSave = 'run'+str(np.asarray(vName).max()+1)\n",
        "          os.mkdir(os.path.join(basePath_ModelSave, run_ModelSave))\n",
        "          os.mkdir(os.path.join(basePath_ModelSave, run_ModelSave, str('Qualitative_Results')))\n",
        "          with open(os.path.join(basePath_ModelSave, run_ModelSave, 'np_random_state.pickle'), 'wb') as f:\n",
        "            pickle.dump(np.random.get_state(), f)\n",
        "        else:\n",
        "          epoch_start = np.asarray([int(x[6:]) for x in sorted(os.listdir(os.path.join(basePath_ModelSave, restore_From))) if x[:6] == 'epoch_']).max()\n",
        "          run_ModelSave = restoreFrom\n",
        "          self.loadWeights(os.path.join(basePath_ModelSave, run_ModelSave,'epoch_'+str(epoch_start)), '')\n",
        "          #print(os.path.join(basePath_ModelSave, run_ModelSave))\n",
        "        log_file = open(os.path.join(basePath_ModelSave, run_ModelSave,\"log.txt\"),\"a+\")\n",
        "        start_time = datetime.datetime.now()\n",
        "\n",
        "        # Adversarial loss ground truths\n",
        "        valid = np.ones((batch_size,) + self.disc_patch)\n",
        "        fake = np.zeros((batch_size,) + self.disc_patch)\n",
        "        imgs_len = int(np.where(imgs_with_masks.shape[0] > imgs_without_masks.shape[0], imgs_with_masks.shape[0], imgs_without_masks.shape[0]))\n",
        "        for epoch in range(epoch_start+1, epochs+1):\n",
        "            #for batch_i, (imgs_A, imgs_B) in enumerate(self.data_loader.load_batch(batch_size)):\n",
        "            rndm_ind_imgs_with_msks = self.getRandomindexes(len(imgs_with_masks), imgs_len, _replace = (imgs_with_masks.shape[0]<imgs_without_masks.shape[0]))\n",
        "            rndm_ind_imgs_without_msks = self.getRandomindexes(len(imgs_without_masks), imgs_len, _replace = (imgs_with_masks.shape[0]>imgs_without_masks.shape[0]))\n",
        "            imgs_with_masks_Augmented = self.random_jitter(imgs_with_masks).reshape(-1, self.img_rows, self.img_cols, self.channels)\n",
        "            imgs_without_masks_Augmented = self.random_jitter(imgs_without_masks).reshape(-1, self.img_rows, self.img_cols, self.channels)\n",
        "            for batch_i in range(imgs_len):#Use batch size as 1\n",
        "                imgs_A = (imgs_with_masks_Augmented[rndm_ind_imgs_with_msks[batch_i]]).reshape(1, self.img_rows, self.img_cols, self.channels)#self.random_jitter(imgs_with_masks[rndm_ind_imgs_with_msks[batch_i]]).reshape(-1, self.img_rows, self.img_cols, self.channels)#imgs_with_masks[(batch_i)*batch_size:(batch_i+1)*batch_size]\n",
        "                imgs_B = (imgs_without_masks_Augmented[rndm_ind_imgs_without_msks[batch_i]]).reshape(1, self.img_rows, self.img_cols, self.channels)#self.random_jitter(imgs_without_masks[rndm_ind_imgs_without_msks[batch_i]]).reshape(-1, self.img_rows, self.img_cols, self.channels)#imgs_without_masks[(batch_i)*batch_size:(batch_i+1)*batch_size]\n",
        "                #print('imgs_A.shape', imgs_A.shape)\n",
        "                #print('imgs_B.shape', imgs_B.shape)\n",
        "                # ----------------------\n",
        "                #  Train Discriminators\n",
        "                # ----------------------\n",
        "\n",
        "                # Translate images to opposite domain\n",
        "                fake_B = self.g_AB.predict(imgs_A)\n",
        "                fake_A = self.g_BA.predict(imgs_B)\n",
        "                fake_A = np.add(fake_A, imgs_B)\n",
        "\n",
        "                # Train the discriminators (original images = real / translated = Fake)\n",
        "                dA_loss_real = self.d_A.train_on_batch(imgs_A, valid)\n",
        "                dA_loss_fake = self.d_A.train_on_batch(fake_A, fake)\n",
        "                dA_loss = 0.5 * np.add(dA_loss_real, dA_loss_fake)\n",
        "\n",
        "                dB_loss_real = self.d_B.train_on_batch(imgs_B, valid)\n",
        "                dB_loss_fake = self.d_B.train_on_batch(fake_B, fake)\n",
        "                dB_loss = 0.5 * np.add(dB_loss_real, dB_loss_fake)\n",
        "\n",
        "                # Total disciminator loss\n",
        "                d_loss = 0.5 * np.add(dA_loss, dB_loss)\n",
        "\n",
        "\n",
        "                # ------------------\n",
        "                #  Train Generators\n",
        "                # ------------------\n",
        "\n",
        "                # Train the generators\n",
        "                g_loss = self.combined.train_on_batch([imgs_A, imgs_B],\n",
        "                                                        [valid, valid,\n",
        "                                                        imgs_A, imgs_B,\n",
        "                                                        imgs_A, imgs_B])\n",
        "\n",
        "                elapsed_time = datetime.datetime.now() - start_time\n",
        "\n",
        "                # Plot the progress\n",
        "                print (\"\\r[Epoch %d/%d] [Batch %d/%d] [D loss: %f, acc: %3d%%] [G loss: %05f, adv: %05f, recon: %05f, id: %05f] time: %s \" \\\n",
        "                                                                        % ( epoch, epochs,\n",
        "                                                                            batch_i+1, imgs_len//batch_size,\n",
        "                                                                            d_loss[0], 100*d_loss[1],\n",
        "                                                                            g_loss[0],\n",
        "                                                                            np.mean(g_loss[1:3]),\n",
        "                                                                            np.mean(g_loss[3:5]),\n",
        "                                                                            np.mean(g_loss[5:6]),\n",
        "                                                                            elapsed_time), end = '')\n",
        "                \n",
        "            log_file.write(\"[Epoch %d/%d] [D loss: %f, acc: %3d%%] [G loss: %05f, adv: %05f, recon: %05f, id: %05f] time: %s \\n\" \\\n",
        "                                                                        % ( epoch, epochs,\n",
        "                                                                            d_loss[0], 100*d_loss[1],\n",
        "                                                                            g_loss[0],\n",
        "                                                                            np.mean(g_loss[1:3]),\n",
        "                                                                            np.mean(g_loss[3:5]),\n",
        "                                                                            np.mean(g_loss[5:6]),\n",
        "                                                                            elapsed_time))\n",
        "            log_file.flush()\n",
        "\n",
        "                # If at save interval => save generated image samples\n",
        "            if epoch % sample_interval == 0:\n",
        "              self.sample_images_Edited(epoch, batch_i, img_save_path=os.path.join(basePath_ModelSave, run_ModelSave, str('Qualitative_Results'),str(epoch)+'.png'))\n",
        "              #self.sample_images(epoch, batch_i)\n",
        "              #self.sample_images_Train(1, 180)\n",
        "\n",
        "            #Save Model and Weights\n",
        "            if epoch%model_save_intervel == 0:\n",
        "              base_dir = os.path.join(basePath_ModelSave, run_ModelSave, 'epoch_'+str(epoch))\n",
        "              #pre_name = 'cycleGANWithoutIdentity_'\n",
        "              pre_name = 'cycleGANIdentityAndUniformNorm_0_1_'\n",
        "              if not os.path.exists(base_dir):\n",
        "                os.makedirs(base_dir)\n",
        "\n",
        "              #Save Discriminator 1\n",
        "              model_json = gan.d_A.to_json()\n",
        "              with open(os.path.join(base_dir, pre_name+\"d_A.json\"), \"w\") as json_file:\n",
        "                  json_file.write(model_json)\n",
        "              # serialize weights to HDF5\n",
        "              gan.d_A.save_weights(os.path.join(base_dir, pre_name+\"d_A.h5\"))\n",
        "              #print(\"Saved model to disk\")\n",
        "\n",
        "              #Save Discriminator 2\n",
        "              model_json = gan.d_B.to_json()\n",
        "              with open(os.path.join(base_dir, pre_name+\"d_B.json\"), \"w\") as json_file:\n",
        "                  json_file.write(model_json)\n",
        "              # serialize weights to HDF5\n",
        "              gan.d_B.save_weights(os.path.join(base_dir, pre_name+\"d_B.h5\"))\n",
        "              #print(\"Saved model to disk\")\n",
        "\n",
        "              #Save Generator AB\n",
        "              model_json = gan.g_AB.to_json()\n",
        "              with open(os.path.join(base_dir, pre_name+\"g_AB.json\"), \"w\") as json_file:\n",
        "                  json_file.write(model_json)\n",
        "              # serialize weights to HDF5\n",
        "              gan.g_AB.save_weights(os.path.join(base_dir, pre_name+\"g_AB.h5\"))\n",
        "              #print(\"Saved model to disk\")\n",
        "\n",
        "              #Save Generator BA\n",
        "              model_json = gan.g_BA.to_json()\n",
        "              with open(os.path.join(base_dir, pre_name+\"g_BA.json\"), \"w\") as json_file:\n",
        "                  json_file.write(model_json)\n",
        "              # serialize weights to HDF5\n",
        "              gan.g_BA.save_weights(os.path.join(base_dir, pre_name+\"g_BA.h5\"))\n",
        "              #print(\"Saved model to disk\")\n",
        "\n",
        "            #End Save Model and Weights\n",
        "        log_file.close()\n",
        "\n",
        "    def sample_images(self, epoch, batch_i):\n",
        "        r, c = 2, 4\n",
        "\n",
        "        #imgs_A = imgs_with_masks[-1:]\n",
        "        imgs_A = imgs_with_masks_test[-1:]\n",
        "        imgs_B = imgs_without_masks[-1:]\n",
        "\n",
        "        # Demo (for GIF)\n",
        "        #imgs_A = self.data_loader.load_img('datasets/apple2orange/testA/n07740461_1541.jpg')\n",
        "        #imgs_B = self.data_loader.load_img('datasets/apple2orange/testB/n07749192_4241.jpg')\n",
        "\n",
        "        # Translate images to the other domain\n",
        "        fake_B = self.g_AB.predict(imgs_A)\n",
        "        fake_A = self.g_BA.predict(imgs_B)\n",
        "        # Translate back to original domain\n",
        "        reconstr_A = self.g_BA.predict(fake_B)\n",
        "        reconstr_B = self.g_AB.predict(np.add(fake_A, imgs_B))\n",
        "        global map0\n",
        "        map0 = reconstr_A\n",
        "        gen_imgs = np.concatenate([imgs_A, fake_B, reconstr_A, np.add(reconstr_A, fake_B), imgs_B, fake_A, np.add(fake_A, imgs_B), reconstr_B])\n",
        "        \n",
        "        # Rescale images 0 - 1\n",
        "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "        titles = [['Original', 'Translated', 'Map', 'Reconstructed'], ['Original', 'Map', 'Translated', 'Reconstructed']]\n",
        "        fig, axs = plt.subplots(r, c, figsize= (15, 10))\n",
        "        cnt = 0\n",
        "        for i in range(r):\n",
        "            for j in range(c):\n",
        "                axs[i,j].imshow(gen_imgs[cnt].squeeze(), cmap='gray')\n",
        "                axs[i, j].set_title(titles[i][j])\n",
        "                axs[i,j].axis('off')\n",
        "                cnt += 1\n",
        "        plt.show()\n",
        "        plt.close()\n",
        "\n",
        "    def sample_images_Only_Infected(self, Indx=0):\n",
        "        r, c = 1, 6\n",
        "\n",
        "        #imgs_A = imgs_with_masks[-1:]\n",
        "        imgs_A = imgs_with_masks_test[Indx:Indx+1]\n",
        "        #imgs_B = imgs_without_masks_test[0:1]\n",
        "        img_msk = imgs_masks_test[Indx:Indx+1]\n",
        " \n",
        "        # Demo (for GIF)\n",
        "        #imgs_A = self.data_loader.load_img('datasets/apple2orange/testA/n07740461_1541.jpg')\n",
        "        #imgs_B = self.data_loader.load_img('datasets/apple2orange/testB/n07749192_4241.jpg')\n",
        "\n",
        "        # Translate images to the other domain\n",
        "        fake_B = self.g_AB.predict(imgs_A)\n",
        "        #fake_A = self.g_AB.predict(imgs_B)\n",
        "        # Translate back to original domain\n",
        "        reconstr_A = self.g_BA.predict(fake_B)\n",
        "        #reconstr_B = self.g_BA.predict(np.add(fake_A, imgs_B))\n",
        "        #reconstr_B = self.g_BA.predict(fake_A)\n",
        "        #global map0\n",
        "        #map0 = reconstr_A\n",
        "        gen_imgs = np.concatenate([imgs_A, fake_B, reconstr_A])\n",
        "        \n",
        "        # Rescale images 0 - 1\n",
        "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "        titles = [['Input (Class: 1)', 'Translated (Class: 0)', 'Map',]]\n",
        "        fig, axs = plt.subplots(r, c, figsize= (21, 6))\n",
        "        cnt = 0\n",
        "        for i in range(r):\n",
        "            for j in range(c-3):\n",
        "                # print(cnt)\n",
        "                # print(gen_imgsshape)\n",
        "                axs[j].imshow(gen_imgs[cnt].squeeze(), cmap='gray')\n",
        "                axs[j].set_title(titles[i][j])\n",
        "                axs[j].axis('off')\n",
        "                cnt += 1\n",
        "            if(i == 0):\n",
        "              hmap = getHeatMap(imgs_A.squeeze(), reconstr_A.squeeze()).squeeze()\n",
        "              axs[4].imshow(hmap)\n",
        "              _, binarymsk = getbinaryMaskFromHeatMap(hmap)\n",
        "              #axs[4].imshow(colormsk, cmap='gray')\n",
        "              axs[3].imshow(binarymsk, cmap='gray')\n",
        "              axs[5].imshow(overlayMaskonImg(imgs_A.astype('float64').reshape(self.img_shape).squeeze(), img_msk.astype('float64').reshape(self.img_shape)))\n",
        "            else:\n",
        "              hmap = getHeatMap(imgs_B.squeeze(), reconstr_B.squeeze()).squeeze()\n",
        "              axs[54].imshow(hmap)\n",
        "              _, binarymsk = getbinaryMaskFromHeatMap(hmap)\n",
        "              #axs[4].imshow(colormsk, cmap='gray')\n",
        "              axs[3].imshow(binarymsk, cmap='gray')\n",
        "              axs[5].imshow(imgs_B.squeeze(), cmap='gray')\n",
        "            axs[4].set_title('HeatMap')\n",
        "            axs[4].axis('off')\n",
        "            #axs[4].set_title('Color Mask')\n",
        "            #axs[4].axis('off')\n",
        "            axs[3].set_title('Binary Mask')\n",
        "            axs[3].axis('off')\n",
        "            axs[5].set_title('GroundTruth')\n",
        "            axs[5].axis('off')\n",
        "        hmap = getHeatMap(imgs_A.squeeze(), reconstr_A.squeeze()).squeeze()\n",
        "        _, binarymsk = getbinaryMaskFromHeatMap(hmap)\n",
        "        plt.savefig('/content/drive/My Drive/ResultsPreparation/synopsisResults_For_Qualitative/Proposed Approach/'+'proposed-GAN'+str(Indx)+'.png')#os.path.join(img_save_path))\n",
        "        \n",
        "        plt.imsave('/content/drive/My Drive/ResultsPreparation/synopsisResults_For_Quantitative/Proposed Approach/'+'proposed-GAN'+str(Indx)+'_original.png', img_msk[i].squeeze(), cmap='gray')\n",
        "        plt.imsave('/content/drive/My Drive/ResultsPreparation/synopsisResults_For_Quantitative/Proposed Approach/'+'proposed-GAN'+str(Indx)+'_predicted.png', binarymsk.squeeze(), cmap='gray')\n",
        "  \n",
        "        plt.show()\n",
        "        plt.close()\n",
        "\n",
        "    def sample_images_Advanced(self, epoch, batch_i, img_save_path):\n",
        "        r, c = 2, 8\n",
        "\n",
        "        #imgs_A = imgs_with_masks[-1:]\n",
        "        imgs_A = imgs_with_masks_test[0:1]\n",
        "        imgs_B = imgs_without_masks_test[0:1]\n",
        "        img_msk = imgs_masks_test[0:1]\n",
        " \n",
        "        # Demo (for GIF)\n",
        "        #imgs_A = self.data_loader.load_img('datasets/apple2orange/testA/n07740461_1541.jpg')\n",
        "        #imgs_B = self.data_loader.load_img('datasets/apple2orange/testB/n07749192_4241.jpg')\n",
        "\n",
        "        # Translate images to the other domain\n",
        "        fake_B = self.g_AB.predict(imgs_A)\n",
        "        fake_A = self.g_AB.predict(imgs_B)\n",
        "        # Translate back to original domain\n",
        "        reconstr_A = self.g_BA.predict(fake_B)\n",
        "        #reconstr_B = self.g_BA.predict(np.add(fake_A, imgs_B))\n",
        "        reconstr_B = self.g_BA.predict(fake_A)\n",
        "        global map0\n",
        "        map0 = reconstr_A\n",
        "        gen_imgs = np.concatenate([imgs_A, fake_B, reconstr_A, np.add(reconstr_A, fake_B), imgs_B, fake_A, reconstr_B, np.add(fake_A, imgs_B)])\n",
        "        \n",
        "        # Rescale images 0 - 1\n",
        "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "        titles = [['Original', 'Translated', 'Map', 'Reconstructed'], ['Original', 'Translated', 'Map', 'Reconstructed']]\n",
        "        fig, axs = plt.subplots(r, c, figsize= (21, 6))\n",
        "        cnt = 0\n",
        "        for i in range(r):\n",
        "            for j in range(c-4):\n",
        "                axs[i,j].imshow(gen_imgs[cnt].squeeze(), cmap='gray')\n",
        "                axs[i, j].set_title(titles[i][j])\n",
        "                axs[i,j].axis('off')\n",
        "                cnt += 1\n",
        "            if(i == 0):\n",
        "              hmap = getHeatMap(imgs_A.squeeze(), reconstr_A.squeeze()).squeeze()\n",
        "              axs[i,4].imshow(hmap)\n",
        "              colormsk, binarymsk = getbinaryMaskFromHeatMap(hmap)\n",
        "              axs[i,5].imshow(colormsk, cmap='gray')\n",
        "              axs[i,6].imshow(binarymsk, cmap='gray')\n",
        "              axs[i,7].imshow(overlayMaskonImg(imgs_A.astype('float64').reshape(self.img_shape).squeeze(), img_msk.astype('float64').reshape(self.img_shape)))\n",
        "            else:\n",
        "              hmap = getHeatMap(imgs_B.squeeze(), reconstr_B.squeeze()).squeeze()\n",
        "              axs[i,4].imshow(hmap)\n",
        "              colormsk, binarymsk = getbinaryMaskFromHeatMap(hmap)\n",
        "              axs[i,5].imshow(colormsk, cmap='gray')\n",
        "              axs[i,6].imshow(binarymsk, cmap='gray')\n",
        "              axs[i,7].imshow(imgs_B.squeeze(), cmap='gray')\n",
        "            axs[i,4].set_title('HeatMap')\n",
        "            axs[i,4].axis('off')\n",
        "            axs[i,5].set_title('Color Mask')\n",
        "            axs[i,5].axis('off')\n",
        "            axs[i,6].set_title('Binary Mask')\n",
        "            axs[i,6].axis('off')\n",
        "            axs[i,7].set_title('GroundTruth')\n",
        "            axs[i,7].axis('off')\n",
        "            \n",
        "        #fig.savefig(\"images/%s/%d_%d.png\" % (self.dataset_name, epoch, batch_i))\n",
        "        fig.savefig(os.path.join(img_save_path))\n",
        "        plt.show()\n",
        "        plt.close()\n",
        "\n",
        "    def loadWeights(self, path, pre_name):\n",
        "      pre_name = os.path.join(path, pre_name)\n",
        "      self.d_A.load_weights(pre_name+\"d_A.h5\")\n",
        "      self.d_B.load_weights(pre_name+\"d_B.h5\")\n",
        "      self.g_AB.load_weights(pre_name+\"g_AB.h5\")\n",
        "      self.g_BA.load_weights(pre_name+\"g_BA.h5\")\n",
        "      print('Loading Weights From', path)\n",
        "\n",
        "\n",
        "    def sample_images_Train(self, ref0, ref1):\n",
        "        print('on train set::')\n",
        "        r, c = 2, 4\n",
        "\n",
        "        imgs_A = imgs_with_masks_test[ref0:ref0+1]\n",
        "        imgs_B = imgs_without_masks[ref1:ref1+1]\n",
        "\n",
        "        # Translate images to the other domain\n",
        "        fake_B = self.g_AB.predict(imgs_A)\n",
        "        fake_A = self.g_BA.predict(imgs_B)\n",
        "        # Translate back to original domain\n",
        "        reconstr_A = self.g_BA.predict(fake_B)\n",
        "        reconstr_B = self.g_AB.predict(np.add(fake_A, imgs_B))\n",
        "        global map1\n",
        "        map1 = reconstr_A\n",
        "        gen_imgs = np.concatenate([imgs_A, fake_B, reconstr_A, np.add(reconstr_A, fake_B), imgs_B, fake_A, np.add(fake_A, imgs_B), reconstr_B])\n",
        "        \n",
        "        # Rescale images 0 - 1\n",
        "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "        titles = [['Original', 'Translated', 'Map', 'Reconstructed'], ['Original', 'Map', 'Translated', 'Reconstructed']]\n",
        "        fig, axs = plt.subplots(r, c, figsize= (15, 10))\n",
        "        cnt = 0\n",
        "        for i in range(r):\n",
        "            for j in range(c):\n",
        "                axs[i,j].imshow(gen_imgs[cnt].squeeze(), cmap='gray')\n",
        "                axs[i, j].set_title(titles[i][j])\n",
        "                axs[i,j].axis('off')\n",
        "                cnt += 1\n",
        "        plt.show()\n",
        "        plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsfUMXGP8Mmm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gan = CycleGAN()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_niXxZxGFOsg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#restore_From = None ##Set run id\n",
        "#gan.train(epochs=20, ModelSavePath='SET_PATH', restoreFrom = restore_From, model_save_intervel=1, batch_size=1, sample_interval=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgyLNIw5EjvB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load weights from specific epoch of saved model in each run\n",
        "#gan.loadWeights('SPECIFY_PATH','')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}